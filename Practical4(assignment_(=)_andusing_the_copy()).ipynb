{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqfDsCXetpHI",
        "outputId": "b633df7f-162a-4178-f806-cbb00bb19c60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using Direct Assigment Operator\n",
            "List 1 : [1, 2, 3, 4]\n",
            "List 2: [1, 2, 3, 4]\n",
            "\n",
            "Using Copy\n",
            "List 3 : [1, 2, 3]\n",
            "List 4: [1, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "#1. Explain the difference between assigning a list to a new variable using direct assignment (=) andusing the copy() method. Provide code examples to illustrate the difference.\n",
        "# Direct Assigment =\n",
        "list1 = [1, 2, 3]\n",
        "list2 = list1\n",
        "list2.append(4)\n",
        "print(f\"\\nUsing Direct Assigment Operator\\nList 1 : {list1}\")\n",
        "print(f\"List 2: {list2}\")\n",
        "\n",
        "# Copy()\n",
        "list3 = [1, 2, 3]\n",
        "list4 = list3.copy()\n",
        "list4.append(4)\n",
        "print(f\"\\nUsing Copy\\nList 3 : {list3}\")\n",
        "print(f\"List 4: {list4}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Write a function extract_nouns(text) that takes a text string as input and returns a list of all nounsin the text. Use NLTK&#39;s part-of-speech tagging for this task.\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "def extract_nouns(text):\n",
        "    words = word_tokenize(text)\n",
        "    tagged_words = pos_tag(words)\n",
        "    nouns = [word for word, pos in tagged_words if pos.startswith('NN')]\n",
        "    return nouns\n",
        "\n",
        "text = \"The cat sat on the mat and the dog barked.\"\n",
        "print(f\"Text > {text}\")\n",
        "print(f\"Nouns are >\\n{extract_nouns(text)}\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGu5gqnSt0DT",
        "outputId": "54d95825-19bb-4995-cbd7-b58c2c313cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text > The cat sat on the mat and the dog barked.\n",
            "Nouns are >\n",
            "['cat', 'mat', 'dog']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Demonstrate how to use list comprehension to create a list of the lengths of each word in a givensentence.\n",
        "sentence = \"This is a sample sentence\"\n",
        "word_lengths = [len(word) for word in sentence.split()]\n",
        "for word in sentence.split():\n",
        "    print(f\"{word}: {len(word)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VNjMa4-t12a",
        "outputId": "185fbbe8-4a41-407f-da2b-f4194a57fa00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This: 4\n",
            "is: 2\n",
            "a: 1\n",
            "sample: 6\n",
            "sentence: 8\n"
          ]
        }
      ]
    }
  ]
}